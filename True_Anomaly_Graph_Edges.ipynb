{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c75dd5-9012-4689-83d2-20db2e5b0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of the code is for all of my imports\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# This allows me to access my flash drive that im working off of\n",
    "os.chdir('/Volumes/Flash Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afe130-89a9-4648-b51f-b080285e252b",
   "metadata": {},
   "outputs": [],
   "source": "# This section loads all CSV files from the directory\n\nPath = '/Volumes/Flash Drive/Saturns rings Research/Data From Center of Ringlets CSV files/Center Median Ringlets'\n\n# Get all CSV files in the directory\ncsv_files = glob.glob(os.path.join(Path, '*.csv'))\n\nprint(f\"Found {len(csv_files)} CSV files:\")\nfor csv_file in csv_files:\n    print(f\"  - {os.path.basename(csv_file)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540ff65a-b579-4813-804f-3a5401167d15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This Section is the formulas to convert from UTC to ET time, im working off of ET time\n",
    "\n",
    "# This formula gets the UTC and ET offset due to leap seconds, number is in seconds\n",
    "def utc_to_et_offset(year):\n",
    "    \"\"\"\n",
    "    Get the offset between UTC and ET (TDB) in seconds for 2008.\n",
    "    \n",
    "    For 2008:\n",
    "    - Leap seconds accumulated by 2008: 33 seconds\n",
    "    - TT-TAI offset: 32.184 seconds\n",
    "    - ET ≈ TDB ≈ TT for most purposes\n",
    "    - So ET - UTC ≈ 33 + 32.184 = 65.184 seconds\n",
    "    \"\"\"\n",
    "    \n",
    "    ls = 33  # Leap Seconds since 2008\n",
    "\n",
    "    # TT - TAI offset is always 32.184 seconds\n",
    "    tt_tai_offset = 32.184\n",
    "    \n",
    "    # ET ≈ TDB ≈ TT = UTC + leap_seconds + 32.184\n",
    "    et_utc_offset = ls + tt_tai_offset\n",
    "    \n",
    "    return et_utc_offset # Seconds\n",
    "\n",
    "# This section of the code converts the UTC Julian Date to ET Julian Date adding in the leap seconds offset\n",
    "def convert_paper_time_to_et(jd_utc):\n",
    "    \"\"\"\n",
    "    Convert the paper's UTC-based Julian Date to ET-based Julian Date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    jd_utc : float\n",
    "        Julian Date in UTC (as used in the paper)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    jd_et : float\n",
    "        Julian Date in Ephemeris Time\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get offset for 2008\n",
    "    et_utc_offset_2008 = utc_to_et_offset(2008)\n",
    "    \n",
    "    # Convert to ET\n",
    "    initial_time = jd_utc + (et_utc_offset_2008 / 86400.0)\n",
    "    \n",
    "    return initial_time # Seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4c11ff-843a-48ca-9166-57db99630e98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This section defines the True Anamoly formula and the radius formula\n",
    "\n",
    "def calculate_radius_true_anomaly(a, e, true_anomaly):\n",
    "    \"\"\"\n",
    "    Calculate the radius at a given true anomaly for a Keplerian ellipse.\n",
    "    \n",
    "    This implements equation (2) from the paper:\n",
    "    r(λ,t) = a(1 - e²) / (1 + e·cos(f))\n",
    "    f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    a : float\n",
    "        Semi-major axis (km)\n",
    "    e : float\n",
    "        Eccentricity (dimensionless, between 0 and 1)\n",
    "    true_anomaly : float or array\n",
    "        True anomaly f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "        where λ is the inertial longitude and ϖ is the longitude of periapse\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    r : float or array\n",
    "        Radius at the given true anomaly (km)\n",
    "    \"\"\"\n",
    "\n",
    "        # Convert to radians\n",
    "    #true_anomaly = true_anomaly * np.pi / 180\n",
    "    \n",
    "    # Calculate the numerator: a(1 - e²)\n",
    "    numerator = a * (1 - e**2)\n",
    "    \n",
    "    # Calculate the denominator: 1 + e·cos(f)\n",
    "    denominator = 1 + e * np.cos(true_anomaly)\n",
    "    \n",
    "    # Calculate radius\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    return r\n",
    "\n",
    "def calculate_true_anomaly(longitude #Inertial longitude (LON value)\n",
    "                           ,varpi_0 # Longitude periapse (Fixed)\n",
    "                           ,varpi_dot #Rrecession rate (Fixed)\n",
    "                           ,time # Time from data\n",
    "                           ,initial_time): # Time from paper (fixed)\n",
    "    \"\"\"\n",
    "    Calculate the true anomaly from orbital parameters.\n",
    "    \n",
    "    From the paper: f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    longitude : float or array\n",
    "        Inertial longitude λ (degrees)\n",
    "    varpi_0 (Longitude periapse) : float\n",
    "        Longitude of periapse at epoch ϖ₀ (degrees)\n",
    "    varpi_dot (precession rate) : float, optional\n",
    "        Apsidal precession rate ϖ̇ (degrees/day)\n",
    "    time : float, optional\n",
    "        Current time (days)\n",
    "    initial_time : float, optional\n",
    "        Epoch time t₀ (days)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    true_anomaly : float or array\n",
    "        True anomaly f (degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # True anomaly is the angle from periapse\n",
    "    true_anomaly = longitude - varpi_0 - varpi_dot * (time - initial_time)\n",
    "\n",
    "    # Wrap to 0-360 degrees\n",
    "    true_anomaly = true_anomaly % 360\n",
    "    \n",
    "    return true_anomaly\n",
    "\n",
    "def plot_r_vs_true_anomaly(true_anomaly, radii, title=f\"\\Radius vs True Anomaly Analysis of Titan Ringlet \\n File: {csv_files}\"):\n",
    "    \"\"\"\n",
    "    Plot radius vs true anomaly.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    true_anomaly : array\n",
    "        True anomaly values in degrees\n",
    "    radii : array\n",
    "        Radius values in km\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(true_anomaly, radii, 'b-', linewidth=2)\n",
    "    plt.xlabel('True Anomaly, f (degrees)')\n",
    "    plt.ylabel('Radius (km)')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de3f5a-f497-4b1c-ae29-078167a3d292",
   "metadata": {},
   "outputs": [],
   "source": "# This section defines static parameters and initializes data storage\n\n# J2000 epoch = JD 2451545.0\nj2000_jd = 2451545.0\n\n# Paper's epoch\npaper_epoch_utc = 2454467.0  # This is in UTC\n\n# Paper's epoch conversion to ET (seconds)\npaper_epoch_jd_et = convert_paper_time_to_et(paper_epoch_utc)\n\n# Static orbital parameters/Paper values (these don't change between occultations)\n# Using median values for center of ringlet\na_paper = 77878.67  # km\ne_paper = 2.88*10**-4\n\n# Median parameters (averaged from inner and outer edge values)\naeI = 17.39    # ae Inner\naeO = 27.20    # ae Outer\nae_median = (aeI + aeO) / 2  # Median ae\n\nvarpi_0I = 270.54  # degrees Inner\nvarpi_0O = 270.70  # degrees Outer\nvarpi_0_median = (varpi_0I + varpi_0O) / 2  # Median longitude of periapse\n\nvarpi_dotI = 22.57503  # ϖ̇ in degrees/day Inner\nvarpi_dotO = 22.57562  # ϖ̇ in degrees/day Outer\nvarpi_dot_median = (varpi_dotI + varpi_dotO) / 2  # Median precession rate\n\n# Initialize lists to store data points from all occultations\n# Single lists for median/center data\nall_true_anomaly = []\nall_radii = []\nall_longitudes = []\nall_times = []\nall_TAUPLUS = []\nall_TAUMINUS = []\nall_csv_names = []"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab41b2e-f9ec-4a54-b59c-310138128a19",
   "metadata": {},
   "outputs": [],
   "source": "# This section loops through all CSV files and processes each one for Titan Ringlet\nprint(f\"\\nProcessing {len(csv_files)} CSV files...\\n\")\n\nfor csv_file in csv_files:\n    csv_name = os.path.basename(csv_file)\n    print(f\"Processing: {csv_name}\")\n    \n    try:\n        # Load data from CSV\n        data = pd.read_csv(csv_file)\n        \n        # Get Titan median/center data (not inner/outer)\n        titan_data = data[data['Ringlet_Position'] == 'Titan']\n        \n        if len(titan_data) == 0:\n            print(f\"  ⚠ No Titan ringlet data found in {csv_name}\")\n            continue\n        \n        # Process Median/Center Data\n        # Extract radius value from CSV\n        a_median = titan_data['Radius'].values[0]\n        \n        # Calculate eccentricity (using median ae from paper then using our radial value)\n        e_median = ae_median / a_median\n        \n        # Get longitude from data\n        longitude_median = titan_data['LON'].values[0]  # LON in degrees\n\n        # Get TAUPLUS from data\n        TAUPLUS_median = titan_data['TAUPLUS'].values[0]  # TAUPLUS\n\n        # Get TAUMINUS from data\n        TAUMINUS_median = titan_data['TAUMINUS'].values[0]  # TAUMINUS\n        \n        # Convert ET time from seconds to days\n        titan_et_days_median = titan_data['ET'].values[0] / 86400.0\n        \n        # Convert to Julian Days\n        titan_jd_et_median = j2000_jd + titan_et_days_median\n        \n        # Calculate true anomaly (comes out in degrees after wrapping)\n        true_anomaly_median = calculate_true_anomaly(longitude_median, varpi_0_median, varpi_dot_median, \n                                             titan_jd_et_median, paper_epoch_jd_et)\n        \n        # Convert to radians before calculating radius\n        true_anomaly_rad_median = true_anomaly_median * np.pi / 180\n        \n        # Calculate radii\n        radii_median = calculate_radius_true_anomaly(a_median, e_median, true_anomaly_rad_median)\n        \n        # Store median/center data points\n        all_true_anomaly.append(true_anomaly_median)\n        all_radii.append(radii_median)\n        all_longitudes.append(longitude_median)\n        all_times.append(titan_jd_et_median)\n        all_TAUPLUS.append(TAUPLUS_median)\n        all_TAUMINUS.append(TAUMINUS_median)\n        \n        print(f\"  ✓ Center/Median: a = {a_median:.2f} km\")\n        \n        all_csv_names.append(csv_name)\n        \n    except Exception as ex:\n        print(f\"  ✗ Error processing {csv_name}: {ex}\")\n        import traceback\n        traceback.print_exc()\n        continue\n\n# Convert lists to numpy arrays\nall_true_anomaly = np.array(all_true_anomaly)\nall_radii = np.array(all_radii)\nall_longitudes = np.array(all_longitudes)\nall_times = np.array(all_times)\nall_TAUPLUS = np.array(all_TAUPLUS)\nall_TAUMINUS = np.array(all_TAUMINUS)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"TOTAL DATA POINTS COLLECTED:\")\nprint(f\"  Center/Median: {len(all_true_anomaly)} points\")\nprint(f\"  Total Tau+- values: {len(all_TAUPLUS) + len(all_TAUMINUS)} values\")\nprint(f\"{'='*60}\")\n\nif len(all_true_anomaly) > 0:\n    print(f\"Center/Median - True anomaly: {np.min(all_true_anomaly):.2f}° to {np.max(all_true_anomaly):.2f}°\")\n    print(f\"Center/Median - Radii: {np.min(all_radii):.2f} to {np.max(all_radii):.2f} km\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384f3ebf-4e8f-4d37-a413-b79d184965d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # This part creates the model curve using paper parameters (Might not need commenting out for now)\\n\\n# Create model curve (sampling all true anomalies)\\ntrue_anomaly_deg_model = np.linspace(0, 360, 1000)\\ntrue_anomaly_rad_model = true_anomaly_deg_model * np.pi / 180\\n\\n# Paper parameters for model\\na_paper = 77867.13  # km\\nae_paper = 17.39    # km \\ne_paper = ae_paper / a_paper\\n\\nmodel_radii = calculate_radius_true_anomaly(a_paper, e_paper, true_anomaly_rad_model)\\n\\nprint(f\"Model parameters:\")\\nprint(f\"  a_paper = {a_paper} km\")\\nprint(f\"  e_paper = {e_paper:.6f}\")\\nprint(f\"  Model radius range: {np.min(model_radii):.2f} to {np.max(model_radii):.2f} km\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # This part creates the model curve using paper parameters (Might not need commenting out for now)\n",
    "\n",
    "# Create model curve (sampling all true anomalies)\n",
    "true_anomaly_deg_model = np.linspace(0, 360, 1000)\n",
    "true_anomaly_rad_model = true_anomaly_deg_model * np.pi / 180\n",
    "\n",
    "# Paper parameters for model\n",
    "a_paper = 77867.13  # km\n",
    "ae_paper = 17.39    # km \n",
    "e_paper = ae_paper / a_paper\n",
    "\n",
    "model_radii = calculate_radius_true_anomaly(a_paper, e_paper, true_anomaly_rad_model)\n",
    "\n",
    "print(f\"Model parameters:\")\n",
    "print(f\"  a_paper = {a_paper} km\")\n",
    "print(f\"  e_paper = {e_paper:.6f}\")\n",
    "print(f\"  Model radius range: {np.min(model_radii):.2f} to {np.max(model_radii):.2f} km\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7139828a-54ac-4c40-b048-6699746fcabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 occultation files:\n",
      "  - BetCen_075I_1km.sav\n",
      "  - BetCen_077E_1km.sav\n",
      "  - BetCen_077I_1km.sav\n",
      "  - BetCen_078E_1km.sav\n",
      "  - BetCen_081I_1km.sav\n",
      "  - BetCen_085I_1km.sav\n",
      "  - BetCen_089I_1km.sav\n",
      "  - BetCen_092E_1km.sav\n",
      "  - BetCen_096I_1km.sav\n",
      "  - BetCen_102I_1km.sav\n",
      "  - BetCen_104E_1km.sav\n",
      "  - BetCen_104I_1km.sav\n",
      "\n",
      "Processing BetCen_075I_1km.sav...\n",
      "  ✓ Successfully extracted data: 72021 data points\n",
      "\n",
      "Processing BetCen_077E_1km.sav...\n",
      "  ✓ Successfully extracted data: 70179 data points\n",
      "\n",
      "Processing BetCen_077I_1km.sav...\n",
      "  ✓ Successfully extracted data: 71561 data points\n",
      "\n",
      "Processing BetCen_078E_1km.sav...\n",
      "  ✓ Successfully extracted data: 86554 data points\n",
      "\n",
      "Processing BetCen_081I_1km.sav...\n",
      "  ✓ Successfully extracted data: 78863 data points\n",
      "\n",
      "Processing BetCen_085I_1km.sav...\n",
      "  ✓ Successfully extracted data: 70303 data points\n",
      "\n",
      "Processing BetCen_089I_1km.sav...\n",
      "  ✓ Successfully extracted data: 70032 data points\n",
      "\n",
      "Processing BetCen_092E_1km.sav...\n",
      "  ✓ Successfully extracted data: 103898 data points\n",
      "\n",
      "Processing BetCen_096I_1km.sav...\n",
      "  ✓ Successfully extracted data: 82885 data points\n",
      "\n",
      "Processing BetCen_102I_1km.sav...\n",
      "  ✓ Successfully extracted data: 70266 data points\n",
      "\n",
      "Processing BetCen_104E_1km.sav...\n",
      "  ✓ Successfully extracted data: 63055 data points\n",
      "\n",
      "Processing BetCen_104I_1km.sav...\n",
      "  ✓ Successfully extracted data: 78357 data points\n",
      "\n",
      "============================================================\n",
      "Extraction complete! Total occultations loaded: 12\n",
      "============================================================\n",
      "075I: 72021 data points\n",
      "077E: 70179 data points\n",
      "077I: 71561 data points\n",
      "078E: 86554 data points\n",
      "081I: 78863 data points\n",
      "085I: 70303 data points\n",
      "089I: 70032 data points\n",
      "092E: 103898 data points\n",
      "096I: 82885 data points\n",
      "102I: 70266 data points\n",
      "104E: 63055 data points\n",
      "104I: 78357 data points\n"
     ]
    }
   ],
   "source": [
    "# Initial approximate locations of the ringlets (Hardcoded)\n",
    "saturn_ringlets_approx = {\n",
    "    'Titan': 77883,      # Colombo Gap - looks accurate in the plot around 77500-78000\n",
    "    'Maxwell': 87500,    # Maxwell Gap - appears correct around 87000-87500\n",
    "    'Bond': 88710,       # Bond Ringlet - looks close, around 88500-89000\n",
    "    'Huygens': 117800,   # Huygens Gap - in the inset, appears around 117500\n",
    "    'Dawes': 90210       # Dawes Ringlet - appears around 90000-90500\n",
    "}\n",
    "\n",
    "# Path to the directory containing all occultation files\n",
    "data_directory = '/Volumes/Flash Drive/Saturns rings Research/Data/BetCen Occultations'\n",
    "\n",
    "# Find all .sav files matching the pattern\n",
    "occultation_files = glob.glob(os.path.join(data_directory, 'BetCen_*_1km.sav'))\n",
    "\n",
    "# Sort the files for consistent ordering\n",
    "occultation_files.sort()\n",
    "\n",
    "print(f\"Found {len(occultation_files)} occultation files:\")\n",
    "for file in occultation_files:\n",
    "    print(f\"  - {os.path.basename(file)}\")\n",
    "\n",
    "# Dictionary to store all extracted data\n",
    "all_occultation_data = {}\n",
    "\n",
    "# Loop through each occultation file\n",
    "for file_path in occultation_files:\n",
    "    # Extract the occultation identifier (e.g., '064E', '105I', etc.)\n",
    "    filename = os.path.basename(file_path)\n",
    "    occultation_id = filename.split('_')[1]  # Gets '064E' from 'BetCen_064E_1km.sav'\n",
    "    \n",
    "    print(f\"\\nProcessing {filename}...\")\n",
    "    \n",
    "    try:\n",
    "        # Read the .sav file\n",
    "        test = sio.readsav(file_path)\n",
    "        \n",
    "        # Extract the data structure\n",
    "        pdsdata = test['pdsdata'][0]\n",
    "        \n",
    "        # Get radius and tau\n",
    "        radius = pdsdata['RADIUS']\n",
    "        tau = pdsdata['TAU']\n",
    "        \n",
    "        # Store the data in the dictionary\n",
    "        all_occultation_data[occultation_id] = {\n",
    "            'filename': filename,\n",
    "            'radius': radius,\n",
    "            'tau': tau,\n",
    "            'full_data': pdsdata  # Store full data structure if you need other fields\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✓ Successfully extracted data: {len(radius)} data points\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Extraction complete! Total occultations loaded: {len(all_occultation_data)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Example: Loop through all occultations\n",
    "for occ_id, data in all_occultation_data.items():\n",
    "    print(f\"{occ_id}: {len(data['radius'])} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983c5f4-4dab-45d3-ae28-e70290b09238",
   "metadata": {},
   "outputs": [],
   "source": "# This section plots the model curve with ALL data points from all occultations for Titan ringlet\n\nplt.figure(figsize=(14, 8))\n\n# Plot median/center data points with error bars (blue circles)\nplt.errorbar(all_true_anomaly, all_radii - a_paper, \n             yerr=[all_TAUMINUS, all_TAUPLUS],  # Asymmetric error bars\n             fmt='bo', markersize=8, capsize=3, capthick=1, \n             label=f'Titan Center/Median ({len(all_true_anomaly)} points)', \n             alpha=0.6, elinewidth=1)\n\n# Formatting\nplt.xlabel('True Anomaly, f (degrees)', fontsize=12)\nplt.ylabel('r - a (km)', fontsize=12)\nplt.title(f'Titan Ringlet - True Anomaly Analysis (Center/Median)\\nCombined data from {len(all_csv_names)} occultations', fontsize=14)\nplt.xlim(0, 360)\nplt.ylim(-50, 70)\nplt.axhline(y=0, color='k', linestyle='--', alpha=0.3, label='a (semi-major axis)')\nplt.legend(fontsize=10, loc='best')\nplt.grid(True, alpha=0.3)\n\n# Add text box with statistics\nstats_text = f'Total points: {len(all_true_anomaly)}\\n'\nstats_text += f'Occultations: {len(all_csv_names)}'\n\nplt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n         fontsize=9, verticalalignment='top', \n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nPlot generated with {len(all_true_anomaly)} total data points from {len(all_csv_names)} CSV files\")\nprint(f\"  - Center/Median: {len(all_true_anomaly)} points (blue circles)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0867a0-d7cb-4975-85ac-8c9d68380611",
   "metadata": {},
   "outputs": [],
   "source": "# This section plots optical depth vs true anomaly for Titan ringlet along with the true anomaly vs radial distance\nfig, ax1 = plt.subplots(figsize=(14, 8))\n\n# PRIMARY AXIS (LEFT Y-AXIS): r - a (km)\nax1.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax1.set_ylabel('r - a (km)', fontsize=12)\nax1.set_xlim(0, 360)\nax1.set_ylim(-50, 70)\n\n# Plot radius data on primary axis\nax1.errorbar(all_true_anomaly, all_radii - a_paper,\n             fmt='bo', markersize=8, capsize=3, capthick=1, \n             label=f'Titan Center/Median ({len(all_true_anomaly)} points)', \n             alpha=0.6, elinewidth=1)\n\n# SECONDARY AXIS (RIGHT Y-AXIS): Optical Depth (τ)\nax2 = ax1.twinx()\nax2.set_ylabel('Optical Depth (τ)', fontsize=12, color='purple')\nax2.tick_params(axis='y', labelcolor='purple')\nax2.set_ylim(-.1, 5)\n\n# Calculate average tau\navg_tau = [(tau_plus + tau_minus) / 2 for tau_plus, tau_minus in zip(all_TAUPLUS, all_TAUMINUS)]\n\n# Plot optical depth data on secondary axis\nax2.errorbar(all_true_anomaly, avg_tau,\n             fmt='ms', markersize=8, capsize=3, capthick=1, \n             label=f'Titan Center/Median Optical Depth ({len(all_true_anomaly)} points)', \n             alpha=0.6, elinewidth=1)\n\n# Formatting\nax1.set_title(f'Titan Ringlet - True Anomaly Analysis (Center/Median)\\nCombined data from {len(all_csv_names)} occultations', fontsize=14)\nax1.axhline(y=0, color='k', linestyle='--', alpha=0.3, label='a (semi-major axis)')\nax1.grid(True, alpha=0.3)\n\n# Combine legends from both axes\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, fontsize=10, loc='best')\n\n# Add text box with statistics\nstats_text = f'Total points: {len(all_true_anomaly)}\\n'\nstats_text += f'Occultations: {len(all_csv_names)}'\nax1.text(0.02, 0.98, stats_text, transform=ax1.transAxes, \n         fontsize=9, verticalalignment='top', \n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585cf17-40a7-4596-b8a9-d47e7a84eee7",
   "metadata": {},
   "outputs": [],
   "source": "# This section plots just optical depth vs true anomaly for Titan ringlet\nplt.figure(figsize=(14, 8))\n\n# Calculate average tau (mean of upper and lower bounds)\navg_tau = [(tau_plus + tau_minus) / 2 for tau_plus, tau_minus in zip(all_TAUPLUS, all_TAUMINUS)]\n\n# Error bars: distance from mean to bounds\ntau_err_lower = [avg - tau_minus for avg, tau_minus in zip(avg_tau, all_TAUMINUS)]\ntau_err_upper = [tau_plus - avg for tau_plus, avg in zip(all_TAUPLUS, avg_tau)]\n\n# Plot median/center data with asymmetric error bars\nplt.errorbar(all_true_anomaly, avg_tau, \n             yerr=[tau_err_lower, tau_err_upper],\n             fmt='bs', markersize=8, capsize=3, capthick=1, \n             label=f'Titan Center/Median Optical Depth ({len(all_true_anomaly)} points)', \n             alpha=0.6, elinewidth=1)\n\n# Formatting\nplt.xlabel('True Anomaly, f (degrees)', fontsize=12)\nplt.ylabel('Optical Depth (τ)', fontsize=12)\nplt.title(f'Titan Ringlet - Optical Depth vs True Anomaly (Center/Median)\\nCombined data from {len(all_csv_names)} occultations', fontsize=14)\nplt.xlim(0, 361)\nplt.ylim(0, 5)  # Adjust based on your tau range\nplt.legend(fontsize=10, loc='best')\nplt.grid(True, alpha=0.3)\n\n# Add text box with statistics\nstats_text = f'Total points: {len(all_true_anomaly)}\\n'\nstats_text += f'Occultations: {len(all_csv_names)}'\nplt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n         fontsize=9, verticalalignment='top', \n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nPlot generated with {len(all_true_anomaly)} total data points from {len(all_csv_names)} CSV files\")\nprint(f\"  - Center/Median: {len(all_true_anomaly)} points (blue squares)\")\n\nprint(\"\\n\" + \"=\" * 60)\n\n# Sort by true anomaly to see the pattern more clearly\ndata_sorted = sorted(zip(all_true_anomaly, avg_tau))\n\nprint(\"\\nCENTER/MEDIAN (sorted by true anomaly):\")\nfor f, tau in data_sorted:\n    print(f\"  f = {f:6.1f}°  ->  τ = {tau:.3f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}