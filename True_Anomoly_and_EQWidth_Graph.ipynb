{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1924cacb-34f4-49c8-9592-fe94066efc0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This section of the code is for all of my imports\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as fits\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# This allows me to access my flash drive that im working off of\n",
    "os.chdir('/Volumes/Flash Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e447c74a-db4a-439f-9c6b-0ab1b8adae9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This Section is the formulas to convert from UTC to ET time, im working off of ET time\n",
    "\n",
    "# This formula gets the UTC and ET offset due to leap seconds, number is in seconds\n",
    "def utc_to_et_offset(year):\n",
    "    \"\"\"\n",
    "    Get the offset between UTC and ET (TDB) in seconds for 2008.\n",
    "    \n",
    "    For 2008:\n",
    "    - Leap seconds accumulated by 2008: 33 seconds\n",
    "    - TT-TAI offset: 32.184 seconds\n",
    "    - ET ≈ TDB ≈ TT for most purposes\n",
    "    - So ET - UTC ≈ 33 + 32.184 = 65.184 seconds\n",
    "    \"\"\"\n",
    "    \n",
    "    ls = 33  # Leap Seconds since 2008\n",
    "\n",
    "    # TT - TAI offset is always 32.184 seconds\n",
    "    tt_tai_offset = 32.184\n",
    "    \n",
    "    # ET ≈ TDB ≈ TT = UTC + leap_seconds + 32.184\n",
    "    et_utc_offset = ls + tt_tai_offset\n",
    "    \n",
    "    return et_utc_offset # Seconds\n",
    "\n",
    "# This section of the code converts the UTC Julian Date to ET Julian Date adding in the leap seconds offset\n",
    "def convert_paper_time_to_et(jd_utc):\n",
    "    \"\"\"\n",
    "    Convert the paper's UTC-based Julian Date to ET-based Julian Date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    jd_utc : float\n",
    "        Julian Date in UTC (as used in the paper)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    jd_et : float\n",
    "        Julian Date in Ephemeris Time\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get offset for 2008\n",
    "    et_utc_offset_2008 = utc_to_et_offset(2008)\n",
    "    \n",
    "    # Convert to ET\n",
    "    initial_time = jd_utc + (et_utc_offset_2008 / 86400.0)\n",
    "    \n",
    "    return initial_time # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8909f18-5425-46a9-8325-9492143e7cec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This section defines the True Anamoly formula and the radius formula\n",
    "\n",
    "def calculate_radius_true_anomaly(a, e, true_anomaly):\n",
    "    \"\"\"\n",
    "    Calculate the radius at a given true anomaly for a Keplerian ellipse.\n",
    "    \n",
    "    This implements equation (2) from the paper:\n",
    "    r(λ,t) = a(1 - e²) / (1 + e·cos(f))\n",
    "    f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    a : float\n",
    "        Semi-major axis (km)\n",
    "    e : float\n",
    "        Eccentricity (dimensionless, between 0 and 1)\n",
    "    true_anomaly : float or array\n",
    "        True anomaly f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "        where λ is the inertial longitude and ϖ is the longitude of periapse\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    r : float or array\n",
    "        Radius at the given true anomaly (km)\n",
    "    \"\"\"\n",
    "\n",
    "        # Convert to radians\n",
    "    #true_anomaly = true_anomaly * np.pi / 180\n",
    "    \n",
    "    # Calculate the numerator: a(1 - e²)\n",
    "    numerator = a * (1 - e**2)\n",
    "    \n",
    "    # Calculate the denominator: 1 + e·cos(f)\n",
    "    denominator = 1 + e * np.cos(true_anomaly)\n",
    "    \n",
    "    # Calculate radius\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    return r\n",
    "\n",
    "def calculate_true_anomaly(longitude #Inertial longitude (LON value)\n",
    "                           ,varpi_0 # Longitude periapse (Fixed)\n",
    "                           ,varpi_dot #Rrecession rate (Fixed)\n",
    "                           ,time # Time from data\n",
    "                           ,initial_time): # Time from paper (fixed)\n",
    "    \"\"\"\n",
    "    Calculate the true anomaly from orbital parameters.\n",
    "    \n",
    "    From the paper: f = λ - ϖ = λ - ϖ₀ - ϖ̇(t - t₀)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    longitude : float or array\n",
    "        Inertial longitude λ (degrees)\n",
    "    varpi_0 (Longitude periapse) : float\n",
    "        Longitude of periapse at epoch ϖ₀ (degrees)\n",
    "    varpi_dot (precession rate) : float, optional\n",
    "        Apsidal precession rate ϖ̇ (degrees/day)\n",
    "    time : float, optional\n",
    "        Current time (days)\n",
    "    initial_time : float, optional\n",
    "        Epoch time t₀ (days)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    true_anomaly : float or array\n",
    "        True anomaly f (degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # True anomaly is the angle from periapse\n",
    "    true_anomaly = longitude - varpi_0 - varpi_dot * (time - initial_time)\n",
    "\n",
    "    # Wrap to 0-360 degrees\n",
    "    true_anomaly = true_anomaly % 360\n",
    "    \n",
    "    return true_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f499b4-9d86-4173-9f2e-2abb8d979f93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This section defines static parameters\n",
    "\n",
    "# J2000 epoch = JD 2451545.0\n",
    "j2000_jd = 2451545.0\n",
    "\n",
    "# Paper's epoch\n",
    "paper_epoch_utc = 2454467.0  # This is in UTC\n",
    "\n",
    "# Paper's epoch conversion to ET (seconds)\n",
    "paper_epoch_jd_et = convert_paper_time_to_et(paper_epoch_utc)\n",
    "\n",
    "# Static orbital parameters/Paper values (these don't change between occultations)\n",
    "# Using median values for center of ringlet\n",
    "a_paper = 77878.67  # km\n",
    "e_paper = 2.88*10**-4\n",
    "\n",
    "# Median parameters (averaged from inner and outer edge values)\n",
    "aeI = 17.39    # ae Inner\n",
    "aeO = 27.20    # ae Outer\n",
    "ae_median = (aeI + aeO) / 2  # Median ae\n",
    "\n",
    "varpi_0I = 270.54  # degrees Inner\n",
    "varpi_0O = 270.70  # degrees Outer\n",
    "varpi_0_median = (varpi_0I + varpi_0O) / 2  # Median longitude of periapse\n",
    "\n",
    "varpi_dotI = 22.57503  # ϖ̇ in degrees/day Inner\n",
    "varpi_dotO = 22.57562  # ϖ̇ in degrees/day Outer\n",
    "varpi_dot_median = (varpi_dotI + varpi_dotO) / 2  # Median precession rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017fdfe-ca68-470f-9cfa-e0a580063606",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": "#This section codes and Graphs the True Anomoly and the EQ Width from the Total Ringlet CSV files\n\n# Define the directory containing your CSV files\ncsv_directory = '/Volumes/Flash Drive/Saturns rings Research/Data From Center of Ringlets CSV files/Total Ringlet/'\n\n# Get all CSV files in the directory\ncsv_files = glob.glob(os.path.join(csv_directory, '*_1km_ringlet_individual_points.csv'))\n\nprint(f\"Found {len(csv_files)} CSV files to process\\n\")\n\n# Use your existing static parameters\nvarpi_0 = varpi_0_median  # 270.62 degrees\nvarpi_dot = varpi_dot_median  # 22.575325 degrees/day\ninitial_time_et = paper_epoch_jd_et  # Already converted to ET\n\n# Bin width in km\nbin_width = 1.0  # km\n\n# Lists to store results from all files\nall_eq_width_results = []\nall_tau_results = []\n\n# Process each CSV file\nfor csv_file in csv_files:\n    csv_name = os.path.basename(csv_file)\n    print(f\"Processing: {csv_name}\")\n    \n    try:\n        # Load data from CSV\n        data = pd.read_csv(csv_file)\n        \n        # Filter for only Titan ringlet data\n        titan_data = data[data['Ringlet'] == 'Titan'].copy()\n        \n        if len(titan_data) == 0:\n            print(f\"  ⚠ No Titan ringlet data found in {csv_name}\")\n            continue\n        \n        # Calculate true anomaly for each data point\n        titan_data['ET_days'] = titan_data['ET'] / 86400.0\n        titan_data['JD_ET'] = j2000_jd + titan_data['ET_days']\n        \n        titan_data['true_anomaly'] = calculate_true_anomaly(\n            longitude=titan_data['LON'],\n            varpi_0=varpi_0,\n            varpi_dot=varpi_dot,\n            time=titan_data['JD_ET'],\n            initial_time=initial_time_et\n        )\n        \n        # Process each unique occultation in this file\n        for occ in titan_data['Occultation'].unique():\n            occ_data = titan_data[titan_data['Occultation'] == occ]\n            \n            # Calculate equivalent width: sum of all optical depths × bin width\n            eq_width = np.sum(occ_data['Tau']) * bin_width\n            \n            # Calculate sum of error bars for equivalent width\n            # TAUPLUS and TAUMINUS are the max/min values, so we need to calculate the difference\n            if 'TAUPLUS' in occ_data.columns and 'TAUMINUS' in occ_data.columns:\n                eq_width_plus = np.sum(np.abs(occ_data['TAUPLUS'] - occ_data['Tau'])) * bin_width\n                eq_width_minus = np.sum(np.abs(occ_data['Tau'] - occ_data['TAUMINUS'])) * bin_width\n            else:\n                eq_width_plus = 0\n                eq_width_minus = 0\n            \n            # Get the true anomaly\n            true_anom = occ_data['true_anomaly'].mean()\n            \n            # Store equivalent width results with error bars\n            all_eq_width_results.append({\n                'occultation': occ,\n                'csv_file': csv_name,\n                'true_anomaly': true_anom,\n                'equivalent_width': eq_width,\n                'eq_width_plus': eq_width_plus,\n                'eq_width_minus': eq_width_minus,\n                'num_points': len(occ_data)\n            })\n            \n            # Store optical depth results with error bars (using median)\n            # Calculate the median tau\n            tau_median = occ_data['Tau'].median()\n            \n            # TAUPLUS and TAUMINUS are max/min values, so calculate the difference\n            if 'TAUPLUS' in occ_data.columns and 'TAUMINUS' in occ_data.columns:\n                tau_plus_median = occ_data['TAUPLUS'].median()\n                tau_minus_median = occ_data['TAUMINUS'].median()\n                tau_plus_error = np.abs(tau_plus_median - tau_median)\n                tau_minus_error = np.abs(tau_median - tau_minus_median)\n            else:\n                tau_plus_error = 0\n                tau_minus_error = 0\n            \n            all_tau_results.append({\n                'occultation': occ,\n                'csv_file': csv_name,\n                'true_anomaly': true_anom,\n                'tau_median': tau_median,\n                'tau_mean': occ_data['Tau'].mean(),\n                'tau_plus': tau_plus_error,\n                'tau_minus': tau_minus_error,\n                'radius_median': occ_data['Radius'].median()\n            })\n        \n        print(f\"  ✓ Processed {len(titan_data)} individual points from {titan_data['Occultation'].nunique()} occultation(s)\")\n        \n    except Exception as ex:\n        print(f\"  ✗ Error processing {csv_name}: {ex}\")\n        import traceback\n        traceback.print_exc()\n        continue\n\n# Convert to DataFrames\neq_width_df = pd.DataFrame(all_eq_width_results).sort_values('true_anomaly')\ntau_df = pd.DataFrame(all_tau_results).sort_values('true_anomaly')\n\nprint(f\"\\n{'='*60}\")\nprint(f\"TOTAL DATA POINTS COLLECTED:\")\nprint(f\"  Number of occultations processed: {len(eq_width_df)}\")\nprint(f\"  CSV files successfully processed: {len(csv_files)}\")\nprint(f\"{'='*60}\")\n\n# ===== WIDTH ANALYSIS - LOOP THROUGH ALL FILES AGAIN =====\nwidth_analysis = []\n\n# Loop through ALL CSV files again to get width info\nfor csv_file in csv_files:\n    try:\n        # Load data from CSV\n        data = pd.read_csv(csv_file)\n        \n        # Filter for only Titan ringlet data\n        titan_data = data[data['Ringlet'] == 'Titan'].copy()\n        \n        if len(titan_data) == 0:\n            continue\n        \n        # Calculate true anomaly for each data point\n        titan_data['ET_days'] = titan_data['ET'] / 86400.0\n        titan_data['JD_ET'] = j2000_jd + titan_data['ET_days']\n        \n        titan_data['true_anomaly'] = calculate_true_anomaly(\n            longitude=titan_data['LON'],\n            varpi_0=varpi_0,\n            varpi_dot=varpi_dot,\n            time=titan_data['JD_ET'],\n            initial_time=initial_time_et\n        )\n        \n        # Process each unique occultation in this file\n        for occ in titan_data['Occultation'].unique():\n            occ_data = titan_data[titan_data['Occultation'] == occ].sort_values('Radius')\n            \n            # Physical width: difference between max and min radius\n            physical_width = occ_data['Radius'].max() - occ_data['Radius'].min()\n            \n            # Peak optical depth\n            peak_tau = occ_data['Tau'].max()\n\n            # Median optical depth\n            median_tau = occ_data['Tau'].median()\n            \n            # Equivalent width\n            eq_width = np.sum(occ_data['Tau']) * 1.0\n            \n            width_analysis.append({\n                'occultation': occ,\n                'true_anomaly': occ_data['true_anomaly'].mean(),\n                'physical_width': physical_width,\n                'peak_tau': peak_tau,\n                'median_tau': median_tau,\n                'eq_width': eq_width\n            })\n    except Exception as ex:\n        continue\n\nwidth_df = pd.DataFrame(width_analysis).sort_values('true_anomaly')\n\n# ===== PLOTTING =====\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n\n# Plot 1: Optical Depth vs True Anomaly with error bars (using median)\nax1.errorbar(tau_df['true_anomaly'], tau_df['tau_median'], \n             yerr=[tau_df['tau_minus'], tau_df['tau_plus']],\n             fmt='o', markersize=6, linewidth=1.5, capsize=3, capthick=1.5)\nax1.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax1.set_ylabel('Optical Depth, τ (median)', fontsize=12)\nax1.set_title('Titan Ringlet Optical Depth vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Equivalent Width vs True Anomaly with error bars (using sum)\nax2.errorbar(eq_width_df['true_anomaly'], eq_width_df['equivalent_width'], \n             yerr=[eq_width_df['eq_width_minus'], eq_width_df['eq_width_plus']],\n             fmt='o', markersize=6, linewidth=1.5, color='red', capsize=3, capthick=1.5)\nax2.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax2.set_ylabel('Equivalent Width (km)', fontsize=12)\nax2.set_title('Titan Ringlet Equivalent Width vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*60}\")\nprint(f\"PHYSICAL WIDTH ANALYSIS:\")\nprint(f\"{'='*60}\")\n\nprint(f\"\\n{'Occultation':<20} {'True Anom (°)':<15} {'Phys Width (km)':<18} {'Peak τ':<12} {'Median τ':<12} {'EQ Width (km)'}\")\nprint(\"-\" * 105)\nfor idx, row in width_df.iterrows():\n    print(f\"{row['occultation']:<20} {row['true_anomaly']:>14.2f} {row['physical_width']:>17.1f} \"\n          f\"{row['peak_tau']:>11.3f} {row['median_tau']:>11.3f} {row['eq_width']:>14.3f}\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"SUMMARY STATISTICS:\")\nprint(f\"  Physical width range: {width_df['physical_width'].min():.1f} - {width_df['physical_width'].max():.1f} km\")\nprint(f\"  Physical width variation: {(width_df['physical_width'].max() - width_df['physical_width'].min()):.1f} km\")\nprint(f\"  Peak τ range: {width_df['peak_tau'].min():.3f} - {width_df['peak_tau'].max():.3f}\")\nprint(f\"  Average τ range: {width_df['median_tau'].min():.3f} - {width_df['median_tau'].max():.3f}\")\nprint(f\"  Equivalent width range: {width_df['eq_width'].min():.1f} - {width_df['eq_width'].max():.1f} km\")\nprint(f\"{'='*60}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e417cd-deaf-4bf2-81f7-f43633188545",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": "# ===== PLOTTING AND SAVING =====\n\n# Define the output directory\noutput_dir = '/Volumes/Flash Drive/Saturns rings Research/Screenshot Outputs/True Anomoly:EQ width Graph and CSV data'\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n\n# Plot 1: Optical Depth vs True Anomaly with error bars (using median)\nax1.errorbar(tau_df['true_anomaly'], tau_df['tau_median'], \n             yerr=[tau_df['tau_minus'], tau_df['tau_plus']],\n             fmt='o', markersize=6, linewidth=1.5, capsize=3, capthick=1.5)\nax1.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax1.set_ylabel('Optical Depth, τ (median)', fontsize=12)\nax1.set_title('Titan Ringlet Optical Depth vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Equivalent Width vs True Anomaly with error bars (using sum)\nax2.errorbar(eq_width_df['true_anomaly'], eq_width_df['equivalent_width'], \n             yerr=[eq_width_df['eq_width_minus'], eq_width_df['eq_width_plus']],\n             fmt='o', markersize=6, linewidth=1.5, color='red', capsize=3, capthick=1.5)\nax2.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax2.set_ylabel('Equivalent Width (km)', fontsize=12)\nax2.set_title('Titan Ringlet Equivalent Width vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\n\n# Save the combined graph\ngraph_filename = os.path.join(output_dir, 'Titan_Ringlet_True_Anomaly_Analysis.png')\nplt.savefig(graph_filename, dpi=300, bbox_inches='tight')\nprint(f\"\\n✓ Saved combined graph to: {graph_filename}\")\n\nplt.show()\n\n# ===== SAVE INDIVIDUAL DATAFRAMES TO CSV =====\n\n# 1. Save Optical Depth data\ntau_csv_filename = os.path.join(output_dir, 'Optical_Depth_vs_True_Anomaly.csv')\ntau_df.to_csv(tau_csv_filename, index=False)\nprint(f\"✓ Saved optical depth data to: {tau_csv_filename}\")\n\n# 2. Save Equivalent Width data\neq_width_csv_filename = os.path.join(output_dir, 'Equivalent_Width_vs_True_Anomaly.csv')\neq_width_df.to_csv(eq_width_csv_filename, index=False)\nprint(f\"✓ Saved equivalent width data to: {eq_width_csv_filename}\")\n\n# 3. Save Physical Width Analysis data\nwidth_csv_filename = os.path.join(output_dir, 'Physical_Width_Analysis.csv')\nwidth_df.to_csv(width_csv_filename, index=False)\nprint(f\"✓ Saved physical width analysis to: {width_csv_filename}\")\n\n# ===== OPTIONAL: SAVE SEPARATE GRAPHS =====\n\n# Save Optical Depth graph separately with error bars (using median)\nfig1, ax1 = plt.subplots(figsize=(12, 6))\nax1.errorbar(tau_df['true_anomaly'], tau_df['tau_median'], \n             yerr=[tau_df['tau_minus'], tau_df['tau_plus']],\n             fmt='o', markersize=6, capsize=3, capthick=1.5)\nax1.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax1.set_ylabel('Optical Depth, τ (median)', fontsize=12)\nax1.set_title('Titan Ringlet Optical Depth vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax1.grid(True, alpha=0.3)\nplt.tight_layout()\noptical_depth_graph = os.path.join(output_dir, 'Optical_Depth_vs_True_Anomaly.png')\nplt.savefig(optical_depth_graph, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved optical depth graph to: {optical_depth_graph}\")\nplt.close()\n\n# Save Equivalent Width graph separately with error bars (using sum)\nfig2, ax2 = plt.subplots(figsize=(12, 6))\nax2.errorbar(eq_width_df['true_anomaly'], eq_width_df['equivalent_width'], \n             yerr=[eq_width_df['eq_width_minus'], eq_width_df['eq_width_plus']],\n             fmt='o', markersize=6, color='red', capsize=3, capthick=1.5)\nax2.set_xlabel('True Anomaly, f (degrees)', fontsize=12)\nax2.set_ylabel('Equivalent Width (km)', fontsize=12)\nax2.set_title('Titan Ringlet Equivalent Width vs True Anomaly Over 12 BetCen Occultations', fontsize=14)\nax2.grid(True, alpha=0.3)\nplt.tight_layout()\neq_width_graph = os.path.join(output_dir, 'Equivalent_Width_vs_True_Anomaly.png')\nplt.savefig(eq_width_graph, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved equivalent width graph to: {eq_width_graph}\")\nplt.close()\n\nprint(f\"\\n{'='*80}\")\nprint(f\"ALL FILES SAVED TO:\")\nprint(f\"  {output_dir}\")\nprint(f\"{'='*80}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fbb38-47d6-43d7-8522-4e9dfda829a2",
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}